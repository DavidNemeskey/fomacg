\documentclass{article}
\usepackage{acl2013}
\usepackage[utf8]{inputenc}
%\usepackage{natbib}
\usepackage{times}
%\usepackage{url}
\usepackage{color}
\usepackage{multirow}
%\usepackage{latexsym}
\usepackage{booktabs,amsmath,multicol}
\usepackage[all]{xy}
\usepackage{dblfloatfix}
\usepackage{tikz}
\usepackage{caption}
\captionsetup{justification=centering}
%\setlength\titlebox{6.5cm}    % You can expand the title box if you
% really have to
% \textheight 685pt 
% \hyphenation{Buda-pest}
% \addtocounter{section}{-1}

\title{Finite-state modeling of general vocabulary}

% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}

\author{D\'avid Nemeskey\\
 HAS Computer and Automation Research Institute, \\
   Kende u 13-17, \\
   H-1111 Budapest\\
 {\tt nemeskey.david@sztaki.mta.hu}
\And
Francis M. Tyers\\
Dept. Lleng. i Sist. Inform.,\\
Universitat d'Alacant,\\
E-03080 Alacant\\
{\tt ftyers@dlsi.ua.es}}

\date{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Submit to:
%   - AFL14    (http://www.inf.u-szeged.hu/afl2014/) -- Mar 14
%   - CIAA2014 (http://www.informatik.uni-giessen.de/ciaa2014/) -- Mar 9
%   - CICLing 15th (http://www.cicling.org/2014/) -- Dec 31 / Jan 7
%   - FSMNLP 2014 (?) -- ??
%
%   Nothing on EACL this year :(
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle\vspace*{-10mm}

\begin{abstract}
  % TODO Add Yli-Jyra:2011
  In recent years, the problem of finite state Constraint Grammar~(CG) parsing has
  received renewed attention. Both \shortcite{Hulden:2011} and
  \shortcite{Peltonen:2011} presented compilers that convert CG rules to finite
  state transducers. While these formalisms serve their purpose as proofs of the
  concept, their performance lags behind other implementations.  %TODO implementionS?
  % TODO I am not talking about compilation, but application
  
  In this paper, we argue that fault lies with using generic finite state
  libraries, and not with the formalisms themselves. We present an open-source
  implementation that capitalizes on the characteristics of CG rule
  application to improve execution time. The implementation achieves performance
  comparable to the current open-source state of the art.
  % TODO OMG this is horrible
\end{abstract}

% TODO: Mans's quadratic claim stands only if bimachine factorization had been
%       performed!
% TODO: Bimanchine factorization, measurements

% TODO: describe Mans's method
% TODO: Apertium stream format, wchar_t vs. char

\section{Introduction}
Outline:
- CG
- FST implementations
- slow or no performance measures
- generic library, implementation can matter
- why we chose Hulden and not Peltonen (application + composition vs intersection)
- 

Our research aims to fill the niche left by the lack of openly accessible finite
state CG implementations.

The 
"VISL CG-3 was 1 500 times faster"

% TODO: related work: Mans (not really "related"), Peltonen, Yli-Jyra

\subsection{fomacg}
% TODO: describe fomacg
The rule transducers act as identity for sentences that 

In the rest of the paper, we present our optimizations in a way that mirrors the
actual development process. We start out with a simple rule engine based on
foma, and improve it step-by-step, benchmarking its performance after each
modification, instead of a single evaluation chapter. We start in
section~\ref{sec:methodology} by describing our evaluation methodology.
Section~\ref{sec:speed} follows the evolution of the rule engine, as it improves
in terms of speed. Section~\ref{sec:complex_idea} contains a complexity analysis
and introduces an idea that theoretically allows us to improve the average- and
best-case asymptotic bound.
Section~\ref{sec:memory} demonstrates how memory savings can be derived from the
steps taken in section~\ref{sec:speed}. Finally, section \ref{sec:conclusion}
contains our conclusions and lists the problems that remain for future work.

%\section{Bridging the Gaps}
%\label{sec:bridging}
%% TODO: what Mans did not cover in his paper (IFF, delimiters)?

\section{Methodology}
\label{sec:methodology}

Apertium includes Constraint Grammars for several
languages\footnote{http://wiki.apertium.org/wiki/Constraint\_grammar}. While
most of these are proper grammars, and are being actually used for morphological
disambiguation in Apertium, they are also too big and complex to be easily used
for the early stages of parser development. Therefore, we have written a small
Hungarian CG, aimed to fully disambiguate a short Hungarian story, which was used
as the development corpus. Since Hungarian is not properly supported by Apertium
yet, morphological analysis was carried out by Hunmorph~\cite{Tron:2005}, and
the tags were translated to the Apertium tagset with a transducer in \texttt{foma}.

The performance of \texttt{fomacg-proc} has been measured against that of
\texttt{cg-proc}, VISL-GC's rule applier. The programs were benchmarked with
three Apertium CG grammars: the toy Hungarian grammar mentioned earlier, the
Breton grammar from the \texttt{br-fr} language pair and the version of the
Finnish grammar due to Karlsson in the \texttt{sme-fin} pair. % TODO: what is sme? Citations!
Seeing that in the early phases, only the Hungarian grammar was used for
development, results for the other two languages are reported only for the later
steps.

Each grammar was run on a test corpus. For Breton, we used the corpus
in the \texttt{br-fr} language pair, which consists of 1,161 sentences. There
are no Finnish and Hungarian corpora in Apertium; for the former, we used a
1,620-sentence excerpt from the 2013-Nov-14 snapshot of the Finnish Wikipedia,
while for the latter, the short test corpus used for grammar development. Since
the latter contains a mere 11 sentences, it was repeated 32 times to produce
a corpus similar in size to the other two. The Breton and Finnish corpora
were tagged by Apertium's morphological analyzer tools.

Since VISL-GC implements CG-3, and fomacg only supports CG-2, a one-to-one
comparison with the grammars above was infeasible. Therefore, we extracted the
subset of rules from each that compiled under fomacg, and carried out the tests
on these subsets. Table~\ref{tab:grammar_size} shows the number of rules in the
original and the CG-2 grammars.

We recorded both initialization and rule application time for the two programs,
via instrumentation in case of \texttt{fomacg-proc} and by running the grammar
first on an empty file and then on the test corpus in case of \texttt{cg-proc}.
However, as initialization is a one-time cost, in the following we are mainly
concerned with the time required for applying rules. The tests were conducted on
a consumer-grade laptop with a 2.2GHz Core2Duo CPU and 4GB RAM, running Linux.
% TODO rewrite this a bit

%TODO: delete the While's, However's, etc.
\section{Performance Optimizations}
\label{sec:speed}

Our implementation, much like that of \texttt{fomacg} (and indeed, all recent
work on finite state CG) is based on the \texttt{foma} library. We started out
with a na誰ve implementation that used solely stock \texttt{foma} functions. Most
of the improvements below stem from the fact that we have replaced these
functions with custom versions that run much faster. The final implementation
abandons \texttt{foma} entirely, but for the data structures. In the future, we
plan to discard those as well, making our code self-contained.

% TODO: declare that it is called fomacg-proc
The program loads the transducers produced by \texttt{fomacg} and applies them
to the text. The input is in the Apertium stream
format\footnote{http://wiki.apertium.org/wiki/Apertium\_stream\_format}
and it is read cohort-by-cohort. A \texttt{foma} FST is used to convert each
cohort to the format expected by the rule transducers, and to convert the final
result back.

To tokenize the text to sentences, we modified \texttt{fomacg} to compile the
\texttt{DELIMITERS} set and emit it as the first FSA in the binary representation
of the grammar. \texttt{fomacg-proc} reads the input until a cohort matches this
set and then sends the accumulated sentence to the rule applier engine.

The rules are tested one-by-one, section-by-section, to see if any of them can
be applied to the text. Once such a rule is found, the associated FST is
executed on the text. As it is possible that a rule that was not applicable to
the original text would run on the modified one, testing is restarted from the
first section after each rule application. The process ends when no more
applicable rules are found.

\subsection{Na誰ve Implementation}
\label{sec:speed_naive}

The first version of the program used the \texttt{apply\_down()} \texttt{foma}
function both for rule application and format conversion. As \texttt{fomacg}
generated a single FST for a rule, rule testing and execution was done in the
same step, by applying the FST. Whether the rule was actually applied or not was
decided by comparing the original sentence to the one returned by the function.

The first row in table~\ref{tab:evaluation} shows the running time for the
Hungarian grammar. At 6.4s, the na誰ve implementation runs more than 20 times
slower than VISL-GC (see table~\ref{tab:grammar_size}). Luckily a far cry from
the 1,500 reported by Peltonen, but clearly too slow to be of practical use.

\subsection{Deletion of Discarded Readings}
\label{sec:speed_deletex}

The original transducers replace the \texttt{\#0\#} in front of discarded readings
with \texttt{\#X\#}. Our first optimization comes from the observation that
deleting these readings instead would not make the transducers any more complex,
but would shorten the resulting sentence, making subsequent tests faster.
Moreover, it allows the engine to recognize actual rule application by simply
testing the length of the output to the input sentence, an operation slightly
faster than byte-for-byte comparison.

Table~\ref{tab:evaluation} reports an approximately 8\% improvement. While not
self-evident, this benefit remained in effect after our subsequent optimizations.

\subsection{FSA-based Rule Testing}
\label{sec:speed_fsa}

Theoretically, further speed-ups could be achieved by separating rule testing
and application, using finite state automata for the former. Automata are faster
than transducers for two reasons: first, there is no need to assemble an output;
and second, a FSA can be determinized and minimized, while \texttt{foma} can
only make a FST deterministic by treating it as a FSA with an alphabet of the
original input:output pairs, which does not entail determinism in the input.

As the third row in table~\ref{tab:evaluation} shows, the idea does not immediately
translate well to practice. The fault lies with the \texttt{apply\_down()}
function, which, being the only method of running a finite state machine in
\texttt{foma}, was designed to support all features of the library. It treats
automata as identity transducers, and fails to capitalize
on the aforementioned advantage of the former. To realize the benefits of
FSA-based testing then, a custom function is required.

\subsection{Custom FSA/FST Application}
\label{sec:speed_custom}

\texttt{apply\_down()} supports the following features: % TODO: \cite{Hulden:2009}?
\begin{itemize}
  \item Conversion of the text to symbols (single- and multi-character)
  \item Regular transitions and flag diacritics
  \item Three types of search in the transition matrix (linear, binary and indexed)
  \item Deterministic and non-deterministic operation
  \item Iterators (multiple invocations iterate the non-deterministic outputs)
\end{itemize}

Our use-case makes most of these features superfluous. \texttt{fomacg} uses
multi-character symbols, but not flag diacritics. To maximize the performance
gains, the rule testing automata must be minimal (hence deterministic), so
there was no need for non-determinism and iterators. Finally, by modifying
\texttt{fomacg} to sort the edges of all grammar machines, we could ensure that
binary transition search alone suffices.
% TODO: explain that indexed is not much better?

The custom FSA applier function that implements only the necessary features
was employed for both rule testing and finding the delimiter cohort. As a result,
running time went down to 1.45 seconds (see table~\ref{tab:evaluation}), a 75\%
improvement.

A similar function was written for input-deterministic minimal transducers.
While not applicable to the non-deterministic rule FSTs, it could
replace \texttt{apply\_down()} for the conversion between the Apertium and  % TODO: eh
the \texttt{fomacg} formats, further reducing the running time to 1.275 seconds.

% TODO: br
What we can take home from the last two sections is that when speed is paramount,
relying blindly on generic libraries may not only lead to suboptimal performance,
but may also produce counterintuitive results (see section~\ref{sec:speed_fsa}).
Conversely, libraries may benefit from including specialized implementations
for different use-cases. For example, \texttt{foma} has all information at hand
to decide if a FST is deterministic, whether it supports binary search or not,
etc. and so, providing specialized functions (even private ones hidden behind
\texttt{apply\_down()}) would improve its performance in certain situations
substantially.

\subsection{Custom FST Application}
\label{sec:speed_fst}

The same custom 

\subsection{One-time Conversion}
\label{sec:speed_convert}

\begin{table}[h]
  \centering
  \caption{Effects of the optimizations on running time}
  \label{tab:evaluation}
  \begin{tabular}{ | l | r | r | }
  \hline
  \textbf{Version} & \textbf{Hungarian} & \textbf{Breton} \\
  \hline
  Na誰ve (\ref{sec:speed_naive})                 & 6.4s   & -- \\
  Delete readings (\ref{sec:speed_deletex})     & 5.9s   & -- \\
  FSA rule testing (\ref{sec:speed_fsa})        & 10s    & -- \\
  Custom FSA runner (\ref{sec:speed_custom})    & 1.45s  &       \\
  Custom format-FST (\ref{sec:speed_custom})    & 1.275s &       \\
  Custom FST runner (\ref{sec:speed_custom})    & 1.45s  &       \\
  Input partitioning (\ref{sec:speed_custom})   & 1.45s  &       \\
  One-time conversion (\ref{sec:speed_convert}) & 0.32s  & 1.55s  \\
  \hline
  \end{tabular}
\end{table}

\section{YYY}
\label{sec:complex_idea}

\subsection{Complexity Analysis}
\label{sec:complex}

Tapanainen~\shortcite{Tapanainen:1999} proves that the worst-case time complexity
for disambiguating a sentence in his CG-2 parser is $\mathcal{O}(n^3k^2G)$,
where $n$ is the length of the sentence, $k$ is the maximum number of readings
per word, and the grammar consists of $G$ rules. The explanation is as follows:
testing a cohort with a single rule can be done in $\mathcal{O}(nk)$; 
the whole sentence in $\mathcal{O}(n^2k)$. This process must be repeated for
each rule, yielding $\mathcal{O}(n^2kG)$. Finally, in the worst case, a rule
only removes a single reading, so it takes $n(k - 1)$ rounds to disambiguate the
sentence, resulting in the aforementioned bound.

% TODO: reported speech?
% TODO: too many 'claim's
Hulden~\shortcite{Hulden:2011} claims that if the rules are compiled to FSTs,
the complexity decreases to $\mathcal{O}(n^2k^2G)$, due to the fact that a
transducer can be applied to a sentence of $nk$ tokens in $\mathcal{O}(nk)$
(linear) time, instead of the $\mathcal{O}(n^2k)$ suggested by Tapanainen.
Unfortunately, we have to refute this claim. It is true that deterministic,
minimal finite-state machines run in time linear in the length of the input,
but a FST representation of a CG rule is necessarily non-deterministic.
Application of such a transducer may require extensive backtracking, making any
claim of linearity unsupportable. Therefore, the worst-case complexity of
Hulden's (and consequently, our) system remains $\mathcal{O}(n^3k^2G)$.
% TODO: proof? (-1#)

This work has improved on two aspects of the complexity, however. First, the
constant in the $\mathcal{O}$ has been decreased as a result of extensive
optimization. Second, rule testing automata have been introduced which, being
deterministic, can indeed by applied in $\mathcal{O}(nk)$ time.
While the worst-case complexity is unaffected, average- and best-case benefit
from the change. Assume that in a round $G_a$ rules can be applied to the
sentence and $G_u$ cannot, $G_a + G_u = G$. With minimal automata for
rule testing the round finishes in $\mathcal{O}(nkG + n^2kG_a)$. Usually
$G_a << G$, and the complexity converges to $\mathcal{O}(nkG)$ for a round
and $\mathcal{O}(n^2k^2G)$ for the whole process; in the best case, when no rule
is applicable, disambiguation finishes in $\mathcal{O}(nkG)$.

It must be noted that ... % TODO: if a rule applies, the round ends

% TODO: Anssi
% TODO: SuperTagger -> prefiltering Finite State to the Rescue (Extended Finite
%       State Models of Language)

\subsection{Beyond the $\mathcal{O}(n^2k^2G)$ Bound}
\label{sec:idea}

Here we present an idea, due to Mans Hulden, that allows the system to
theoretically overcome the $\mathcal{O}(n^2k^2G)$ average complexity bound.
This section describes the method, and investigates its feasibility; the
next section contains the evaluation.

The idea is based on the fact that regular languages are closed under the union
operator. If there are two automata, $FSA_{G_a}$ and $FSA_{G_b}$ that test the
rules $G_a$ and $G_b$, respectively, then it follows that their union,
$FSA_{G_{ab}}$, accepts a sentence iff either $G_a$ or $G_b$ is applicable to it.
If $FSA_{G_{ab}}$ is minimized, it runs in $\mathcal{O}(nk)$ time, the same as
$FSA_{G_a}$ and $FSA_{G_b}$.

% TODO: allows us -> enables decreasing?
The union FSA allows us to decrease the number of rule checks. In this example,
testing if any of the two rules match a sentence with only the original
automata requires a check with both. Instead, we can apply $FSA_{G_{ab}}$ first.
If neither rule is applicable, the automaton will not accept the sentence, and
no further testing is required. If one of the rules is, $FSA_{G_a}$ (or
equivalently, $FSA_{G_b}$) must be run against the sentence to see which. In
practice, if we pick two rules from a CG in random, we shall find that the
majority of the sentences will not match either, hence the number of tests may
be reduced substantially.

There is no need to stop here: we can take two union automata, and merge them
again. It is easy to see that if we represent the rule testing automata in a
graph, where a node is a FSA, and two nodes are connected iff one was created
from the other via union, then we get a binary tree. For a grammar of $G$ rules,
a binary tree of $logG$ levels can be built. Such a tree can confirm with a
single test if a sentence does not match any of the rules, or find the matching
rule in $logG + 1$ tests, if one does. Accordingly, in theory this method
allows us to improve the average- and best-case complexity bounds of the system
to $\mathcal{O}(n^2k^2logG)$ and $\mathcal{O}(nk)$, respectively.  % TODO: rewrite this
(Clearly, for grammars with several sections, instead of a single tree that
contains all rules, one tree must be built for each section to preserve rule
priorities. However, this does not affect the reasoning above.)  % TODO: reasoning?

The bottleneck in this method is memory consumption. The size of the FSA
resulting from a non-deterministic union operation is simply the sum of the
sizes of the original automata. To achieve the speed-up described above, however,
the rule checking automata must be determinized, which may blow up their size
exponentially. Therefore, building a single tree from all rules is infeasible.
A compromise solution is to construct a forest of 2--4 level trees, which still
fits into the memory and provides the same benefit as a single tree, though to
a smaller extent.

\subsection{Evaluation}

The forest can be assembled in several ways; we experimented with two simple
algorithms. Both take as input a list of rule testing automata, which are
encapsulated into single-node trees. Before each step, the trees are sorted by
the size of the FSA in their roots.  % TODO FSAs?

The first algorithm, \textit{SmallestFirst}, unifies the two smallest trees in
each step, until the root FSA in each tree is above a size limit (1000 states in
our case).
The second, \textit{FixedLevel}, aims to create full, balanced binary trees:
in a single step, it unifies the smallest tree with the largest, the second
smallest with the second largest, etc, and repeats the process until the trees
reach a predefined height.

Table~\ref{tab:trees}

\section{Memory Savings}
\label{sec:memory}

% TODO introduction here?

\subsection{Token Matching}
\label{sec:sub_token}

The transition from text to integer representation of the $\Sigma$ alphabet
has also opened a way to decrease the storage space requirements of the grammar.
Once again, the improvement stems not from theoretical, but practical
considerations, and it concerns the conversion of text into tokens in $\Sigma$.
Usually this step is taken for granted in the literature, but implementations
must allocate resources to tackle this task.  % in their own way.

% TODO describe the trie (e.g. byte-based, 256-way, etc.)
In \texttt{foma}, token matching is performed by a trie built from the symbols
in the automaton's alphabet. Depending on the number and length of the symbols
in bytes, this trie may be responsible for a considerable portion of the memory
footprint of an automaton. Given the number of rules in an average CG grammar,
it is easy to see how this trivial sub-task may affect the memory consumption of
the application, as well as the size of the grammar binary.

Since in our system, the job of token matching has been delegated to the symbol
automaton (see section \ref{sec:speed_convert}), there is no need to maintain
separate tries for all individual FSAs. 
% TODO: to not even save them? grammar binary size?

% TODO: number of: singular or plural?
Table \ref{tab:sigma_memory} presents the resulting memory savings.
We report numbers for the raw grammars (L1), as well as for two- and three-level
condition trees (L2-3). It is not surprising that the raw grammars see the
largest improvements; here the tries accounted for 70-80\% of the memory
usage. As the trees get higher, the number of states and edges grows more
rapidly than does the number of tries and the savings become more modest; however,
the approximately 30\% achieved for a three-level condition tree is still
substantial.  % TODO: what?

\subsection{Economizing Condition Trees}

% TODO lots of -> ???
As already mentioned in section \ref{sec:idea}, while conditions trees speed up
rule matching, they also take up lots of space. The main reason is, as we have
seen, the pace with which the size of the merged rule testing automata grows.
There is, however, another factor at work here: each tree contains a
FSA in each of its nodes. For a tree of $L$ levels, this translates to $2^L - 1$
automata. Of course, the automata lower in the tree are much -- possibly
exponentially -- smaller than the ones at the top, but in practice their
contribution is not negligible.

On closer inspection, however, we can see that it is not necessary to have a
condition check in each node. If we are at a non-leaf node $N$ with children
$L$ and $R$ that matches the condition, it is enough to check if the FSA in
$L$ accepts the sentence; if not, we can automatically assume that $R$ does.
Hence, we removed the condition automata in the right branches of all non-leaf
nodes, thereby decreasing the number of condition FSAs to $2^{L-1}$. To maximize
the effect, if the condition FSA on the left branch was bigger than the one on
the right, the branches were swapped.

Table \ref{tab:XXX} shows the results.
% TODO: apparently I haven't implemented this yet! :)

\subsection{FSA Compression}

Although the memory saving techniques described in the last two sections help to
keep the memory consumption of the grammar in control, the potentially
exponential increase in size of the merged rule condition FSAs still prohibits
the building of arbitrary large trees, and thereby prevents us from reaching
the theoretical bound $\mathcal{O}(n^2k^2logG)$. The foma library already
implements some storage compression methods, such as representing the transition
matrix in row-indexed form, similarly to the method described in Kiraz~\shortcite{Kiraz:2001}.
Therefore, to make the idea in section~\ref{sec:idea} feasible, an algorithm that
can compress FSAs aggressively is required. % TODO word order
In this section, we survey the literature in order to find such a method.
% TODO: compute the sparsity of our FSAs? (Kiraz)

Automata Mista, due to Huet~\shortcite{Huet:2003,Huet:2005}, is an applicative
method for describing finite state machines. It represents the FSA or FST as
a forest of tries, each corresponding to a deterministic subset of the paths in
the state space. Non-deterministic transitions and loops are handled by
"jumping" to an arbitrary node in the forest, which is located via a global or a
local addressing scheme. The trie format supports compression in two ways: it
facilitates path sharing and the compact representation can further shrink the
state space by merging non-branching paths. This technique managed to decrease
the size of a Sanskrit lexicon by 87.1\%~\cite{Huet:2005}.

XXX et al.~\shortcite{XXX:2014} present an algorithm for lossless
hyperminimisation of lexical transducers using automatically induced flag
diacritics. The idea behind the algorithm is to replace rightward continuations
with setting the corresponding flag. The authors report savings between
12.6--96.6\%.

% TODO: analyzer or analyser? minimi[sz]ation?
The above methods have similar characteristics that prevent us to apply them to
our case. First, both are aimed at optimizing mostly deterministic, loop-free
automata, such as those created for morphological analyzers. Second, both rely
on techniques that are beyond the power of the simple automaton interpreter
we are using (tries for Automata Mista and flag diacritics for XXX), and which
may incur significant runtime costs; indeed, the hyperminimized transducers run
12-200 times slower than the original ones~\cite{XXX:2014}. 

A task-specific framework, one based on inward deterministic automata has
been proposed for CG parsing~\cite{Yli-Jyra:2011}. The paper reports a binary
size similar to the original grammar size. However, as the framework breaks away
from the practice of direct rule application followed in this paper and
in~\cite{Hulden:2011,Peltonen:2011}, closer inspection remains for future work. 

% TODO: read
%       Reducing memory requirements in reachability-based finite automata operations (http://onlinelibrary.wiley.com/doi/10.1002/spe.561/abstract)
%       On the state complexity of semi-quantum finite automata (http://arxiv.org/abs/1307.2499)
%       State Complexity Research and Approximation (http://link.springer.com/chapter/10.1007/978-3-642-22321-1_5)
%       State Complexity: Recent Results and Open Problems (http://iospress.metapress.com/content/veemqfxm6n48cpxn/)
%       Experiments with Automata Compression (http://link.springer.com/chapter/10.1007/3-540-44674-5_8)

% TODO move these tables to where they should be
\begin{table*}[h]
  \centering
  \caption{Grammar sizes with the running time and binary size of the respective
           VISL-GC grammars}
  \label{tab:grammar_size}
  \begin{tabular}{ | l | r | r | r | r | }
  \hline
  \textbf{Language} & \textbf{Rules} & \textbf{CG-2 rules} &
  \textbf{Binary} & \textbf{Time} \\
  \hline
  Hungarian & &   35 &   8kB & 0.284s \\
  Breton    & &  226 &  36kB & 0.77s \\
  Finnish   & & 1172 & 184kB & 1.78s \\    % TODO: test sme-fin for running time!!!
  \hline
  \end{tabular}
\end{table*}

\begin{table*}[h]
  \centering
  \caption{Performance and storage requirements of rule testing trees\\
           \textsuperscript{*}State count limit was 500\hspace{3em}
           \textsuperscript{+}Did not fit into memory}
  \label{tab:trees}
  \begin{tabular}{ | l | r | r | r | r | r | }
  \hline
  \textbf{Language} & \textbf{Algorithm} & \textbf{Initialization} &
  \textbf{Disambiguation} & \textbf{Memory} & \textbf{File Size} \\
  \hline
  Hungarian & (flat) & 0.028s & 0.32s & 0.5\% & 60kB \\
  Hungarian & FixedLevel(3) & 0.77s & 0.235s & 2.1\% & 7.1MB \\
  Hungarian & Smallest First & 0.62s & 0.234s & 1.9\% & 5.9MB \\
  Breton    & (flat) & 0.5s & 1.55s & 5.1\% & 1.5MB \\
  Breton    & FixedLevel(2) & 1.8s & 1.09s & 9.6\% & 7.4MB \\
  Breton    & Smallest First & 11.14s & 1.05s & 28.7\% & 60MB \\
  Finnish   & (flat) & 1.5s & 22.87s & 21.8\% & 7.2MB \\
  Finnish   & FixedLevel(2) & 3.64s & 13.28s & 32.3\% & 28MB \\
  Finnish   & SmallestFirst\textsuperscript{*} & 20.75s & 9.95s & --\textsuperscript{+} & 198MB \\
  \hline
  \end{tabular}
\end{table*}

\begin{table}[h]
  \centering
  \caption{Improvements in memory usage due to removing the sigma trie. Memory
           consumption is measured as a percentage of the 4GB system memory}
  \label{tab:sigma_memory}
  \begin{tabular}{ | l | r | r | r | }
  \hline
  \textbf{Language} & \textbf{Before} & \textbf{After} & \textbf{Reduction} \\
  \hline
  hun L1 & 0.5\% & 0.1\% & 80\% \\
  hun L3 & 2.1\% & 1.5\% & 28.57\% \\
  br L1 & 5.1\% & 1.3\% & 74.5\% \\
  br L2 & 9.6\% & 4.4\% & 54.16\% \\
  fin L1 & 21\% & 4.1\% & 80.47\% \\
  fin L2 & 32.3\% & 8.9\% & 72.44\% \\
  \hline
  \end{tabular}
\end{table}

\section{Conclusions}
\label{sec:conclusion}
Outline:
\begin{itemize}
\item Implementation matters.
\item We've made some real advances on the state-of-the-art free/open-source
  FST implementations of CG. 
\item Here we need to describe how we are going to reduce the size problem.
\end{itemize}
% TODO: Read and add Yli-Jyra:2011 -- a different method (I also was thinking
%       about a two-step method, where the first level converts cohorts to 
%       some representation (the sets it contains, etc.), and the second level
%       does something else).
While our experiments may have concluded in a negative tone, ...

\section*{Acknowledgements}
This research was conducted under the Google Summer of Code 2013 project
Rule-based finite-state disambiguation\footnote{https://google-melange.appspot.com/gsoc/project/google
/gsoc2013/davidnemeskey/14002}. The authors would like to thank Mans Hulden for
his insights.

% TODO: citations:
\cite{Karlsson:1990} % Karlsson:1990: the Finnish grammar
\cite{Hulden:2011} % Hulden:2011: Mans's paper
\cite{Peltonen:2011} % Peltonen:2011: the other try... should we include it at all?
\cite{Tapanainen:1996} % Tapanainen:1996: CG-2

\bibliographystyle{acl}
\bibliography{apertium_cg}
\end{document}
