\documentclass{article}
\usepackage{acl2013}
\usepackage[utf8]{inputenc}
%\usepackage{natbib}
\usepackage{times}
%\usepackage{url}
\usepackage{color}
\usepackage{multirow}
%\usepackage{latexsym}
\usepackage{booktabs,amsmath,multicol}
\usepackage[all]{xy}
\usepackage{dblfloatfix}
\usepackage{tikz}
%\setlength\titlebox{6.5cm}    % You can expand the title box if you
% really have to
% \textheight 685pt 
% \hyphenation{Buda-pest}
% \addtocounter{section}{-1}

\title{Finite-state modeling of general vocabulary}

% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}

\author{D\'avid Nemeskey\\
 HAS Computer and Automation Research Institute, \\
   Kende u 13-17, \\
   H-1111 Budapest\\
 {\tt nemeskey.david@sztaki.mta.hu}
\And
Francis M. Tyers\\
Dept. Lleng. i Sist. Inform.,\\
Universitat d'Alacant,\\
E-03080 Alacant\\
{\tt ftyers@dlsi.ua.es}}

\date{}

\begin{document}
\maketitle\vspace*{-10mm}

\begin{abstract}
  % TODO Add Yli-Jyra:2011
  In recent years, the problem of finite state Constraint Grammar~(CG) parsing has
  received renewed attention. Both \shortcite{Hulden:2011} and
  \shortcite{Peltonen:2011} presented compilers that convert CG rules to finite
  state transducers. While these formalisms serve their purpose as proofs of the
  concept, their performance lags behind other implementations.  %TODO implementionS?
  % TODO I am not talking about compilation, but application
  
  In this paper, we argue that fault lies with using generic finite state
  libraries, and not with the formalisms themselves. We present an open-source
  implementation that capitalizes on the characteristics of CG rule
  application to improve execution time. The implementation achieves performance
  comparable to the current open-source state of the art.
  % TODO OMG this is horrible
\end{abstract}

\section{Introduction}
Outline:
- CG
- FST implementations
- slow or no performance measures
- generic library, implementation can matter
- why we chose Hulden and not Peltonen (application + composition vs intersection)
- 
% TODO: related work: Mans (not really "related"), 

\section{Bridging the Gaps}
\label{sec:bridging}
% TODO: what Mans did not cover in his paper (IFF, delimiters)?

\section{Implementation}
\label{sec:implementation}

\section{Evaluation}
\label{sec:evaluation}

\subsection{Methodology}
% TDOO fomacg_proc vs fomacg-proc
The performance of \texttt{fomacg\_proc} has been measured against that of
\texttt{cg-proc}, VISL-GC's rule applier. The programs were run on three
Apertium CG grammars: the toy Hungarian grammar used for development, the Breton
grammar from the \texttt{br-fr} language pair and the version of the Finnish
grammar due to Karlsson in the \texttt{sme-fin} pair. % TODO: what is sme? Citations!
% TODO: the corpora we run the grammars on
The tests were conducted on a consumer-grade laptop with a 2.2GHz Core2Duo CPU
and 4GB RAM, running Linux.

Since VISL-GC uses CG-3, and fomacg only supports CG-2, a one-to-one comparison
with the grammars above was infeasible. Therefore, we extracted the subset of
rules from each that compiled under fomacg, and carried out the tests on these
subsets. Table~\ref{tab:grammar-size} shows the number of rules in the original
and the CG-2 grammars.

In the following, we are mainly concerned with the time required for rule
application. However, while we could separate the initialization and execution
times for \texttt{fomacg\_proc}, we could not do the same for \texttt{cg-proc},
and therefore we decided to compare the rule application time of
\texttt{fomacg\_proc} with the full running time of \texttt{cg-proc}.
While this may seem unfair, initialization is a one-time cost and gets
proportionally smaller as the input grows; furthermore, the size of the VISL-GC
grammar binaries is so small that the loading time is negligible.

- table of the grammars: %TODO: VISL-GC grammar binary size?
  hun | | 35 
  br  | | 226
  fin | | 1176

\subsection{Results}
% TODO: AND scalability, or should it be a separate section?

\section{Conclusions}
\label{sec:conclusion}
Outline:
\begin{itemize}
\item Implementation matters.
\item We've made some real advances on the state-of-the-art free/open-source
  FST implementations of CG. 
\item Here we need to describe how we are going to reduce the size problem.
\end{itemize}
% TODO: Read and add Yli-Jyra:2011 -- a different method (I also was thinking
%       about a two-step method, where the first level converts cohorts to 
%       some representation (the sets it contains, etc.), and the second level
%       does something else).

\section*{Acknowledgements}
This research was conducted under the Google Summer of Code 2013 project
Rule-based finite-state disambiguation\footnote{https://google-melange.appspot.com/gsoc/project/google
/gsoc2013/davidnemeskey/14002}.

% TODO: citations:
\cite{Karlsson:1990} % Karlsson:1990: the Finnish grammar
\cite{Hulden:2011} % Hulden:2011: Mans's paper
\cite{Peltonen:2011} % Peltonen:2011: the other try... should we include it at all?
\cite{Tapanainen:1996} % Tapanainen:1996: CG-2

\bibliographystyle{acl}
\bibliography{apertium_cg}
\end{document}
