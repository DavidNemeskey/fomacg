% $Header: /home/vedranm/bitbucket/beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 90e850259b8b 2007/01/28 20:48:30 tantau $

\documentclass[utf8x,t,aspectratio=169]{beamer}

\mode<presentation>
{
%  \usetheme[height=7mm]{Rochester}
  \usetheme{Rochester}
  \useinnertheme{rounded}
%  \useoutertheme{infolines}
  % or ...

  \setbeamercovered{transparent}
}
\usefonttheme[onlymath]{serif}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

%% to draw trees without jpg figures
%\usepackage{synttree}
% For code blocks
% for sane tabular handling
\usepackage{array}
% For strikethrough (normalem keeps it as emph)
%\usepackage[normalem]{ulem}

\usepackage{mathrsfs}
\usepackage{bm}  % For bold math

\newcommand{\vitem}{\item \vspace{4pt}}
\newcommand{\nyil}{$\rightarrow$\ }
\newcommand{\nagytilde}{$\sim$}
\newtheorem{Examplee}{Example}[section]

\newtheorem{nix}{}[section]

\title{Why implementation matters}
\subtitle{Evaluation of an open-source constraint grammar parser}

\author{Dávid Márk Nemeskey\inst{1}, Francis M. Tyers\inst{2}, Mans Hulden\inst{3}}
\institute{
  \inst{1} Institute for Computer Science and Control, Hungarian Academy of Sciences \\
  \inst{2} HSL-fakultetet, UiT Norgga árktalaš universitehta \\
  \inst{3} Department of Linguistics, University of Colorado Boulder}

\date % (optional)
{25th August 2014}

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}

\pgfdeclareimage[height=1.5cm]{apertium-logo}{apertium.png}
\logo{\pgfuseimage{apertium-logo}}

%\AtBeginSection[]
%{
%   \begin{frame}
%       \frametitle{Outline}
%       \tableofcontents[currentsection]
%   \end{frame}
%}
%

% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 
%\beamerdefaultoverlayspecification{<+->}

\setbeamertemplate{navigation symbols}{}%remove navigation symbols

\begin{document}

% TODO: do we need an outline?
\begin{frame}{}
  \titlepage
\end{frame}

\section{Introduction}

% What is CG?
% Apertium & VISL-CG; CG vs n-grame? 
\begin{frame}{Apertium}

\begin{itemize}
  \item Rule-based machine translation platform
  \item Over 40 released language pairs
  \item Free/open-source: GPL licence
  \item Many language pairs include constraint grammars
  \begin{itemize}
    \item All pairs with constraint grammars use VISL CG-3
  \end{itemize} 
\end{itemize}

\end{frame}

\begin{frame}{Constraint Grammar}

% history

\textbf{History:}
\begin{itemize}
  \item Introduced by Fred Karlsson (1995)
  \item ...
\end{itemize}

\textbf{Implementations:}
\begin{itemize}
  \item CG:
  \item CG-2:
  \item VISL CG:
  \item VISL CG3:
\end{itemize}


\textbf{Other relevant literature:}
\begin{itemize}
  \item Voutilainen
  \item ...
\end{itemize}

\end{frame}

% CG-2 & CG-3 (might be skippable)
% Aims: measure actual speed of CG-based MD; faster CG-based MD; beat VISL-CG

\section{fomacg}

\section{Methodology}

\begin{frame}{Development}
The performance has been measured against VISL-CG.


\begin{itemize}
    \vitem Breton
    \vitem Finnish
\end{itemize}
\end{frame}

\section{Generic optimisations}

\begin{frame}{Naïve baseline}
\end{frame}

% TODO composition?

\begin{frame}{Discarded readings}
The original rule FSTs keep discarded readings, only prepend them with \texttt{\#X\#}.

If we delete them:
\begin{itemize}
    \vitem after each rule application, the sentence gets shorter
    \vitem subsequent rules can be applied faster
    \vitem we can detect rule applications easier.
\end{itemize}
This simple change improves running time to 5.9s (8\%).

\end{frame}

\begin{frame}{Rule testing}
Further speed-ups could be achieved by separating rule testing and application:
\begin{itemize}
    \vitem an FSA tests if the rule is applicable
    \vitem the rule FST is only applied if it is
\end{itemize}
Automata are faster than tranducers:
\begin{itemize}
    \vitem no output is generated
    \vitem can be determinised and minimised
\end{itemize}
\only<2-3>{After implementing it...
\begin{itemize}
    \vitem running time goes up to 9 seconds!
    \only<3>{\vitem Why?}
\end{itemize}}
\end{frame}

\begin{frame}{Foma is too generic}

The \texttt{foma} library supports the following features:
\begin{itemize}
  \vitem Conversion of the text to symbols (single- and multi-character)
  \vitem Regular transitions and flag diacritics
  \vitem Three types of search in the transition matrix (linear, binary and indexed)
  \vitem Deterministic and non-deterministic operation
  \vitem Iterators (multiple invocations iterate the non-deterministic outputs)
  \vitem Transducer output
\end{itemize}
%When we run a FSA, all these features are taken into account.
\end{frame}

\begin{frame}{Cut down on features}

\setbeamercovered{transparent}
What we actually need...
\begin{itemize}
  \vitem Conversion of the text to symbols (single- and multi-character)
  \vitem Regular transitions \uncover<1>{and flag diacritics}
  \vitem \uncover<1-2>{Three types of} search in the transition matrix (\uncover<1-2>{linear, }binary\uncover<1-2>{ and indexed})
  \vitem Deterministic \uncover<1-3>{and non-deterministic }operation
  \vitem \uncover<1-4>{Iterators (multiple invocations iterate the non-deterministic outputs)}
  \vitem \uncover<1-5>{Transducer output}
\end{itemize}

\only<7>{Implementing our own functions may improve performance.}
\end{frame}

\begin{frame}{Performance of our custom functions}
Deterministic FSA
\begin{itemize}
    \vitem rule \& delimiter testers
    \vitem 1.45s--75\% improvement!
\end{itemize}
Deterministic FST
\begin{itemize}
    \vitem format conversion
    \vitem 1.275s
\end{itemize}
Non-deterministic functional FST
\begin{itemize}
    \vitem rule transducers
    \vitem 1.05s
\end{itemize}

\end{frame}

\begin{frame}{Learnings}
Genericity is useful:
\begin{itemize}
    \vitem it allows a library to be used in many situations  % TODO Ugh
\end{itemize}

When performance is important, relying on generic libraries
\begin{itemize}
    \vitem leads to suboptimal performance
    \vitem produces counterintuitive results
\end{itemize}

When doing research, it is important to use software the behaviour of which
reflects theory.

\end{frame}

\section{CG-specific optimisations}

\begin{frame}{CG-specific optimisations}
The changes thus were agnostic to the structure of the CG parsing task:
\begin{itemize}
    \vitem decreasing input length
    \vitem using automata for rule testing
    \vitem using custom functions
\end{itemize}

\only<2>{
The rule FSAs \& FSTs have special properties:
\begin{itemize}
    \vitem multicharacter symbols, separated by spaces 
    \vitem common symbols:
    \begin{itemize}
        \vitem boilerplate (\texttt{\$0\$}, \texttt{\#X\#}, etc.)
        \vitem POS, words (\texttt{N}, \texttt{the}, etc.)
    \end{itemize}
\end{itemize}
}
\end{frame}

\begin{frame}{String vector machines}
Symbols are multicharacter, with spaces between them (e.g.
\texttt{\$0\$ "as" \#BOC\# | \#X\# "as" <ADV> | \#0\# "as" <PREP> | \#EOC\#})
\begin{itemize}
    \vitem Our FSTs are $char* \rightarrow char*$
    \vitem String to symbol vector transformation occurs on each FSA/FST application
\end{itemize}
Why not do it in a preprocessing step?
\begin{itemize}
    \vitem Do the transformation only once
    \vitem Rewrite the FSTs to $StringVect \rightarrow StringVect$
\end{itemize}
Variable effectiveness: 4--40\%.
\end{frame}

\begin{frame}{String to symbol conversion}
Internally foma uses integer symbol ids, so a $String \rightarrow int$ conversion
is still performed separately by each FSA/FSTs.
\begin{itemize}
    \vitem Usually taken for granted in the literature
    \vitem Significant contribution to execution time (60\%)
\end{itemize}
\only<2>{
foma uses per-FST tries to do the conversion
\begin{itemize}
    \vitem Doing a single conversion is fast, but it adds up
    \vitem Duplicated trie branches: boilerplate, CG tags
    \vitem High memory consumption
\end{itemize}
}
\end{frame}

\begin{frame}{Converter transducer}
Do the conversion only once in a converter transducer $C$:
\begin{itemize}
    \vitem $\Sigma_c = \displaystyle \bigcup_{i=0}^N{\Sigma_{R_i}}$
    \vitem $C: String \rightarrow int$
\end{itemize}
Rest of the machines are simply $R_i: int \rightarrow int$.
\begin{itemize}
    \vitem Running time improved by 40--70\%.
    \vitem Memory consumption reduced by 75--80\%.
\end{itemize}
\end{frame}

\section{Complexity analysis}

\begin{frame}{Complexity analysis}
Tapanainen proves that worst-case time complexity for a CG parser is
$\mathcal{O}(n^3k^2G)$, where
\begin{itemize}
    \vitem 
\end{itemize}
\end{frame}

\begin{frame}{Rule testing vs application}

\begin{tabular}{| l | l | l | l |}
\hline
\textbf{Language} & \textbf{Testing} & \textbf{Application} & \textbf{Other} \\
\hline
Hungarian & 112,416 / 45.84\% & 2,560 / 7.20\% & 13,760 / 22.75\% \\
Breton & 612,006 / 62.40\% & 4,707 / 2.74\% & 11,921 / 4.41\% \\
Finnish & 6,290,609 / 87.17\% & ~0\% & 81,017 / 3.57\% \\
\hline
\end{tabular}

\end{frame}

\section{Conclusions}

% Aims: Success, Success, Failure (yet)
% logG method (not feasible)
% to take home: implementation matters


\begin{frame}

\bigskip

\bigskip

{\huge Thank you for your attention!}

\bigskip
\bigskip
\bigskip

emails: \\ {\tt nemeskey.david@gmail.com \\ francis.tyers@uit.no \\ mans.hulden@colorado.edu} \\

\end{frame}

\end{document}


